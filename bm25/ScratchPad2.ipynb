{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scratchpad for BM25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "import math\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Simple tokenize per word function\n",
    "tokenize = lambda doc: doc.lower().split(\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Sample documents \n",
    "# Note: Edited doc_1 purposely to show failure of tfidf later\n",
    "document_0 = \"China has a strong economy that is growing at a rapid pace. However politically it differs greatly from the US Economy.\"\n",
    "document_1 = \"At last, China seems serious about confronting an endemic problem: domestic violence and corruption.#Rohan edit China China China China\"\n",
    "document_2 = \"Japan's prime minister, Shinzo Abe, is working towards healing the economic turmoil in his own country for his view on the future of his people.\"\n",
    "document_3 = \"Vladimir Putin is working hard to fix the economy in Russia as the Ruble has tumbled.\"\n",
    "document_4 = \"What's the future of Abenomics? We asked Shinzo Abe for his views\"\n",
    "document_5 = \"Obama has eased sanctions on Cuba while accelerating those against the Russian Economy, even as the Ruble's value falls almost daily.\"\n",
    "document_6 = \"Vladimir Putin was found to be riding a horse, again, without a shirt on while hunting deer. Vladimir Putin always seems so serious about things - even riding horses.\"\n",
    "\n",
    "# List of all documents\n",
    "all_documents = [document_0, document_1, document_2, document_3, document_4, document_5, document_6]\n",
    "\n",
    "# Tokenize each document\n",
    "tokenized_documents = [tokenize(d) for d in all_documents]\n",
    "\n",
    "# print tokenized_documents[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Created 'query' assuming all the preprocessing is done.\n",
    "query = ['china','strong','economy'] # A part of doc_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get the term frequencies for each word in the query against all docs as a sparse matrix\n",
    "def get_term_frequencies(query, tokenized_document):\n",
    "    lis = []\n",
    "    m = len(tokenized_document)\n",
    "    n = len(query)\n",
    "    for i in range(len(tokenized_document)):\n",
    "        for j in query:\n",
    "            lis.append(tokenized_document[i].count(j))\n",
    "    term_frequencies = np.array(lis).reshape(m,n)\n",
    "    return term_frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 1, 1],\n",
       "       [5, 0, 0],\n",
       "       [0, 0, 0],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 0],\n",
       "       [0, 0, 0],\n",
       "       [0, 0, 0]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf = get_term_frequencies(query,tokenized_documents)\n",
    "tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Note:\n",
    "> doc_1 has higher tf. But our query is for doc_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Calculate the IDF for each word against the all documents. Save it as a key-value pair\n",
    "def inverse_document_frequencies(tokenized_documents):\n",
    "    idf_values = dict()\n",
    "    all_tokens_set = set([item for sublist in tokenized_documents for item in sublist])\n",
    "    for tkn in all_tokens_set:\n",
    "        contains_token = map(lambda doc: tkn in doc, tokenized_documents)\n",
    "        idf_values[tkn] = 1 + math.log(len(tokenized_documents)/(sum(contains_token)))\n",
    "    return idf_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get the idf vector for our query from the IDF dictionary\n",
    "def get_idfs_for_query(query=['china','strong','economy']):\n",
    "    idf_values = inverse_document_frequencies(tokenized_documents)\n",
    "    lis = []\n",
    "    n = len(query)\n",
    "    for token in query:\n",
    "        for key, value in idf_values.items():\n",
    "            if token == key:\n",
    "#                 print token,value\n",
    "                lis.append(value)\n",
    "    idfs_for_query = np.array(lis).reshape(n,1)\n",
    "    return idfs_for_query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2.25276297],\n",
       "       [ 2.94591015],\n",
       "       [ 2.25276297]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idf = get_idfs_for_query()\n",
    "idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get the tfidf scores for each token in the query\n",
    "def get_tfidf(tf,idf):\n",
    "    tfidf = np.dot(tf,idf) #initialise tfidf\n",
    "    return tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  7.45143609],\n",
       "       [ 11.26381484],\n",
       "       [  0.        ],\n",
       "       [  2.25276297],\n",
       "       [  0.        ],\n",
       "       [  0.        ],\n",
       "       [  0.        ]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf = get_tfidf(tf,idf)\n",
    "tfidf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Note:\n",
    "> According to TFIDF, doc_1 is the best recommendation, while our query is more relevant to doc_0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BM25\n",
    "***\n",
    "Formula\n",
    "\n",
    "> BM25 = IDF * ((k + 1) * tf) / (k * (1.0 - b + b * (L) + tf)\n",
    "\n",
    "- k = 1.2\n",
    "- b = 0.75\n",
    "- L = |d|/avgDl  ---> DocumentLength/Avg(DocumentLength)\n",
    "\n",
    "Ref : http://opensourceconnections.com/blog/2015/10/16/bm25-the-next-generation-of-lucene-relevation/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Avg length of all documents <for BM25>\n",
    "totlen = 0\n",
    "for i in all_documents:\n",
    "    totlen += len(i)\n",
    "avglen = totlen/len(all_documents)\n",
    "\n",
    "# L = (document length)/(average length of all doc) <for BM25>\n",
    "L = list(len(i)/avglen for i in all_documents)\n",
    "\n",
    "# Constants <for BM25>\n",
    "k = 1.2\n",
    "b = 0.75"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get the bm25 scores \n",
    "def get_bm25_scores(tf,idf):\n",
    "    bm25 = 0\n",
    "    lis = []\n",
    "    for i in range(len(tf)):\n",
    "        for j in range(len(query)):\n",
    "            x = (idf[j]*((k+1)*tf[i][j])/(k*(1.0-b+b*L[i]+tf[i][j])))\n",
    "            bm25 = bm25 + x\n",
    "        lis.append(bm25)\n",
    "        x = 0\n",
    "        bm25 = 0\n",
    "    return lis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([ 6.87308484]),\n",
       " array([ 3.39265389]),\n",
       " array([ 0.]),\n",
       " array([ 2.32436241]),\n",
       " array([ 0.]),\n",
       " array([ 0.]),\n",
       " array([ 0.])]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bm25vec = get_bm25_scores(tf,idf)\n",
    "bm25vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Note:\n",
    "> BM25 gives high weightage to doc_0 as it is the most relevant for our query"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What next ?\n",
    "***\n",
    "\n",
    "- For Relevancy:\n",
    "I was thinking, we could get these scores next to their corresponding documents, sort them and pick the best 3 ?\n",
    "\n",
    "- For Sentiments:\n",
    "Before bm25, sentiments would go as a new column altogether."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
